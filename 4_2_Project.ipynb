{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading a dataset\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "miXBhK5CiOK3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrBI-fB2d7UM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/test 2.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Data Understanding\n"
      ],
      "metadata": {
        "id": "7R0HUruPibUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df.describe()\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "zXek2UTOiUsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "R6KpgKjNiyhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical ‚Üí median\n",
        "num_cols = df.select_dtypes(include=['int64','float64']).columns\n",
        "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
        "\n",
        "# Categorical ‚Üí mode\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in cat_cols:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)\n"
      ],
      "metadata": {
        "id": "6Wi1qQwvi20f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding Categorical Features"
      ],
      "metadata": {
        "id": "ctxLUHk7i-J7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    df[col] = le.fit_transform(df[col])\n"
      ],
      "metadata": {
        "id": "mZDik5nsi_RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature‚ÄìTarget Split"
      ],
      "metadata": {
        "id": "HgdIULp9jJJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(\"Attrition\", axis=1)\n",
        "y = df[\"Attrition\"]\n"
      ],
      "metadata": {
        "id": "tdM-dE9jjKQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train‚ÄìTest Split"
      ],
      "metadata": {
        "id": "LatEOVUIjNhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "YLocVwACjREq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total samples:\", X.shape[0])\n",
        "print(\"Training samples:\", X_train.shape[0])\n",
        "print(\"Testing samples:\", X_test.shape[0])\n",
        "\n",
        "print(\"\\nTraining target shape:\", y_train.shape)\n",
        "print(\"Testing target shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "pa38KqtDjja0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train attrition ratio:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nTest attrition ratio:\")\n",
        "print(y_test.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "KN63YeABjn_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection (Using Random Forest Importance)"
      ],
      "metadata": {
        "id": "qpoDq5BNkNgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "rf_fs = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_fs.fit(X_train, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"Feature\": X_train.columns,\n",
        "    \"Importance\": rf_fs.feature_importances_\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "feature_importance\n"
      ],
      "metadata": {
        "id": "KSn7QGhvkO3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select Important Features (Above Mean Importance)"
      ],
      "metadata": {
        "id": "_2Tr73rfnA8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = feature_importance[\"Importance\"].mean()\n",
        "\n",
        "selected_features = feature_importance[\n",
        "    feature_importance[\"Importance\"] > threshold\n",
        "][\"Feature\"].tolist()\n",
        "\n",
        "print(\"Important Features Used for Training:\\n\")\n",
        "for f in selected_features:\n",
        "    print(f)\n",
        "\n",
        "print(\"\\nTotal original features:\", X_train.shape[1])\n",
        "print(\"Selected important features:\", len(selected_features))\n"
      ],
      "metadata": {
        "id": "CfT2RTI6m8Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduce Dataset to Important Features"
      ],
      "metadata": {
        "id": "w5hzEunZnPxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sel = X_train[selected_features]\n",
        "X_test_sel = X_test[selected_features]\n"
      ],
      "metadata": {
        "id": "Ox5BxvfdnRR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Models Using Selected Features"
      ],
      "metadata": {
        "id": "pwlKznVVnY4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**"
      ],
      "metadata": {
        "id": "T7m390Q7n2sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Decision Tree Training & Evaluation\n",
        "# ===============================\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1Ô∏è‚É£ Train Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train_sel, y_train)\n",
        "\n",
        "# 2Ô∏è‚É£ Predictions\n",
        "y_pred_dt = dt.predict(X_test_sel)\n",
        "y_prob_dt = dt.predict_proba(X_test_sel)[:, 1]\n",
        "\n",
        "# 3Ô∏è‚É£ Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "print(\"Decision Tree Accuracy:\", accuracy)\n",
        "\n",
        "# 4Ô∏è‚É£ Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_dt)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Decision Tree Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 5Ô∏è‚É£ Precision, Recall, F1 Score\n",
        "precision = precision_score(y_test, y_pred_dt)\n",
        "recall = recall_score(y_test, y_pred_dt)\n",
        "f1 = f1_score(y_test, y_pred_dt)\n",
        "\n",
        "print(\"\\nPrecision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# 6Ô∏è‚É£ Classification Report\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "# 7Ô∏è‚É£ ROC‚ÄìAUC Score\n",
        "auc = roc_auc_score(y_test, y_prob_dt)\n",
        "print(\"ROC-AUC Score:\", auc)\n",
        "\n",
        "# 8Ô∏è‚É£ ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_dt)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"Decision Tree (AUC = {auc:.2f})\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve ‚Äì Decision Tree\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# üîπ High-Risk Employee Detection\n",
        "# ===============================\n",
        "\n",
        "risk_df = X_test_sel.copy()\n",
        "risk_df[\"Attrition_Probability\"] = y_prob_dt\n",
        "risk_df[\"Risk_Level\"] = risk_df[\"Attrition_Probability\"].apply(\n",
        "    lambda x: \"High Risk\" if x >= 0.7 else \"Low Risk\"\n",
        ")\n",
        "\n",
        "print(\"\\nHigh-Risk Employees (Top 5):\")\n",
        "print(risk_df.sort_values(\"Attrition_Probability\", ascending=False).head())"
      ],
      "metadata": {
        "id": "Ftz1mtxqGpPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19524118"
      },
      "source": [
        "**SHAP ANALYSIS (Decision Tree)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c30707a"
      },
      "source": [
        "# ===============================\n",
        "# SHAP Analysis for Decision Tree (FINAL & ERROR-FREE)\n",
        "# Compatible with SHAP v0.20+\n",
        "# ===============================\n",
        "\n",
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "# The 'dt' model is now defined from the previous cell\n",
        "model = dt\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values = explainer.shap_values(X_test_sel)\n",
        "\n",
        "# ===============================\n",
        "# Handle SHAP output safely\n",
        "# ===============================\n",
        "\n",
        "if isinstance(shap_values, list):\n",
        "    # Binary classification (class 1 = Attrition)\n",
        "    shap_vals = shap_values[1]\n",
        "    base_value = explainer.expected_value[1]\n",
        "else:\n",
        "    # New SHAP versions (3D array)\n",
        "    shap_vals = shap_values[:, :, 1]\n",
        "    base_value = explainer.expected_value[1] # Select expected value for class 1\n",
        "\n",
        "# ===============================\n",
        "# 1Ô∏è‚É£ Global Feature Importance\n",
        "# ===============================\n",
        "\n",
        "shap.summary_plot(shap_vals, X_test_sel)\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ Feature Importance (Bar Plot)\n",
        "# ===============================\n",
        "\n",
        "shap.summary_plot(shap_vals, X_test_sel, plot_type=\"bar\")\n",
        "\n",
        "# ===============================\n",
        "# 3Ô∏è‚É£ Individual Employee Explanation\n",
        "# ===============================\n",
        "\n",
        "employee_index = 4  # change index if required\n",
        "\n",
        "shap.plots.force(\n",
        "    base_value,\n",
        "    shap_vals[employee_index],\n",
        "    X_test_sel.iloc[employee_index]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random forest**"
      ],
      "metadata": {
        "id": "BhpcXRtovis4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Random Forest Training, Risk Detection & Evaluation\n",
        "# ===============================\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1Ô∏è‚É£ Train Random Forest\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train_sel, y_train)\n",
        "\n",
        "# 2Ô∏è‚É£ Predictions\n",
        "y_pred_rf = rf.predict(X_test_sel)\n",
        "y_prob_rf = rf.predict_proba(X_test_sel)[:, 1]\n",
        "\n",
        "# 3Ô∏è‚É£ Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest Accuracy:\", accuracy)\n",
        "\n",
        "# 4Ô∏è‚É£ Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Random Forest Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 5Ô∏è‚É£ Precision, Recall, F1 Score\n",
        "precision = precision_score(y_test, y_pred_rf)\n",
        "recall = recall_score(y_test, y_pred_rf)\n",
        "f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\nPrecision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# 6Ô∏è‚É£ Classification Report\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# 7Ô∏è‚É£ ROC‚ÄìAUC Score\n",
        "auc = roc_auc_score(y_test, y_prob_rf)\n",
        "print(\"ROC-AUC Score:\", auc)\n",
        "\n",
        "# 8Ô∏è‚É£ ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_rf)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"Random Forest (AUC = {auc:.2f})\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve ‚Äì Random Forest\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# üîπ High-Risk Employee Detection\n",
        "# ===============================\n",
        "\n",
        "risk_df = X_test_sel.copy()\n",
        "risk_df[\"Attrition_Probability\"] = y_prob_rf\n",
        "risk_df[\"Risk_Level\"] = risk_df[\"Attrition_Probability\"].apply(\n",
        "    lambda x: \"High Risk\" if x >= 0.7 else \"Low Risk\"\n",
        ")\n",
        "\n",
        "print(\"\\nHigh-Risk Employees (Top 5):\")\n",
        "risk_df.sort_values(\"Attrition_Probability\", ascending=False).head()\n"
      ],
      "metadata": {
        "id": "w2cj6Y88vCYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# SHAP Analysis for RANDOM FOREST (v0.20+ SAFE)\n",
        "# ===============================\n",
        "\n",
        "import shap\n",
        "\n",
        "# Use trained Random Forest model\n",
        "model = rf\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# IMPORTANT: new SHAP API\n",
        "shap_values = explainer(X_test_sel)\n",
        "\n",
        "# ===============================\n",
        "# 1Ô∏è‚É£ Global Feature Importance\n",
        "# ===============================\n",
        "\n",
        "shap.summary_plot(\n",
        "    shap_values.values[:, :, 1], # Select SHAP values for class 1 for all samples\n",
        "    X_test_sel\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ Feature Importance (Bar Plot)\n",
        "# ===============================\n",
        "\n",
        "shap.summary_plot(\n",
        "    shap_values.values[:, :, 1], # Select SHAP values for class 1 for all samples\n",
        "    X_test_sel,\n",
        "    plot_type=\"bar\"\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 3Ô∏è‚É£ Individual Employee Explanation\n",
        "# ===============================\n",
        "\n",
        "employee_index = 4  # change if required\n",
        "\n",
        "shap.plots.waterfall(\n",
        "    shap.Explanation(\n",
        "        values=shap_values.values[employee_index, :, 1], # Select SHAP values for employee_index, all features, class 1\n",
        "        base_values=explainer.expected_value[1],\n",
        "        data=X_test_sel.iloc[employee_index],\n",
        "        feature_names=X_test_sel.columns\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "w3dx5WkGvt4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN**"
      ],
      "metadata": {
        "id": "e06fljx42VoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# ANN Training, Risk Detection & Evaluation\n",
        "# ===============================\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# ===============================\n",
        "# 1Ô∏è‚É£ Feature Scaling (MANDATORY for ANN)\n",
        "# ===============================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_ann = scaler.fit_transform(X_train_sel)\n",
        "X_test_ann = scaler.transform(X_test_sel)\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ Train ANN Model\n",
        "# ===============================\n",
        "\n",
        "ann = MLPClassifier(\n",
        "    hidden_layer_sizes=(64, 32),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=500,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "ann.fit(X_train_ann, y_train)\n",
        "\n",
        "# ===============================\n",
        "# 3Ô∏è‚É£ Predictions\n",
        "# ===============================\n",
        "\n",
        "y_pred_ann = ann.predict(X_test_ann)\n",
        "y_prob_ann = ann.predict_proba(X_test_ann)[:, 1]\n",
        "\n",
        "# ===============================\n",
        "# 4Ô∏è‚É£ Evaluation Metrics\n",
        "# ===============================\n",
        "\n",
        "print(\"ANN Accuracy:\", accuracy_score(y_test, y_pred_ann))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_ann))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_ann))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_ann))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob_ann))\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_ann))\n",
        "\n",
        "# ===============================\n",
        "# 5Ô∏è‚É£ Confusion Matrix\n",
        "# ===============================\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_ann)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"ANN Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 6Ô∏è‚É£ ROC Curve\n",
        "# ===============================\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_ann)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"ANN (AUC = {roc_auc_score(y_test, y_prob_ann):.2f})\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve ‚Äì ANN\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 7Ô∏è‚É£ High-Risk Employee Detection\n",
        "# ===============================\n",
        "\n",
        "risk_df_ann = X_test_sel.copy()\n",
        "risk_df_ann[\"Attrition_Probability\"] = y_prob_ann\n",
        "risk_df_ann[\"Risk_Level\"] = risk_df_ann[\"Attrition_Probability\"].apply(\n",
        "    lambda x: \"High Risk\" if x >= 0.7 else \"Low Risk\"\n",
        ")\n",
        "\n",
        "print(\"\\nHigh-Risk Employees (Top 5):\")\n",
        "risk_df_ann.sort_values(\"Attrition_Probability\", ascending=False).head()\n"
      ],
      "metadata": {
        "id": "QtgtyHXZ2VRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# ANN + SHAP (KernelExplainer) ‚Äì FINAL FIX\n",
        "# ===============================\n",
        "\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Background data (scaled)\n",
        "# -------------------------------\n",
        "background = X_train_ann[\n",
        "    np.random.choice(X_train_ann.shape[0], 50, replace=False)\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ KernelExplainer\n",
        "# -------------------------------\n",
        "explainer = shap.KernelExplainer(\n",
        "    ann.predict_proba,\n",
        "    background\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Explain a small test subset (scaled)\n",
        "# -------------------------------\n",
        "X_test_sample_ann = X_test_ann[:50]\n",
        "\n",
        "shap_values = explainer.shap_values(X_test_sample_ann)\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ Convert scaled data to DataFrame (IMPORTANT)\n",
        "# -------------------------------\n",
        "X_test_sample_df = pd.DataFrame(\n",
        "    X_test_sample_ann,\n",
        "    columns=X_test_sel.columns\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 5Ô∏è‚É£ Global Feature Importance\n",
        "# -------------------------------\n",
        "shap.summary_plot(\n",
        "    shap_values[:, :, 1], # Corrected: Select SHAP values for class 1 for all samples\n",
        "    X_test_sample_df\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 6Ô∏è‚É£ Feature Importance (Bar Plot)\n",
        "# -------------------------------\n",
        "shap.summary_plot(\n",
        "    shap_values[:, :, 1], # Corrected: Select SHAP values for class 1 for all samples\n",
        "    X_test_sample_df,\n",
        "    plot_type=\"bar\"\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 7Ô∏è‚É£ Individual Employee Explanation\n",
        "# -------------------------------\n",
        "employee_index = 4\n",
        "\n",
        "shap.plots.waterfall(\n",
        "    shap.Explanation(\n",
        "        values=shap_values[employee_index, :, 1], # Corrected: Select SHAP values for employee_index, all features, class 1\n",
        "        base_values=explainer.expected_value[1],\n",
        "        data=X_test_sample_df.iloc[employee_index],\n",
        "        feature_names=X_test_sample_df.columns\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "vYNh6fYI2nrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XG-Boost**"
      ],
      "metadata": {
        "id": "WiE4S3Az3-hU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# XGBoost Training, Risk Detection & Evaluation\n",
        "# ===============================\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1Ô∏è‚É£ Train XGBoost\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "xgb_model.fit(X_train_sel, y_train)\n",
        "\n",
        "# 2Ô∏è‚É£ Predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test_sel)\n",
        "y_prob_xgb = xgb_model.predict_proba(X_test_sel)[:, 1]\n",
        "\n",
        "# 3Ô∏è‚É£ Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"XGBoost Accuracy:\", accuracy)\n",
        "\n",
        "# 4Ô∏è‚É£ Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_xgb)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"XGBoost Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 5Ô∏è‚É£ Precision, Recall, F1 Score\n",
        "precision = precision_score(y_test, y_pred_xgb)\n",
        "recall = recall_score(y_test, y_pred_xgb)\n",
        "f1 = f1_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(\"\\nPrecision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# 6Ô∏è‚É£ Classification Report\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "\n",
        "# 7Ô∏è‚É£ ROC‚ÄìAUC Score\n",
        "auc = roc_auc_score(y_test, y_prob_xgb)\n",
        "print(\"ROC-AUC Score:\", auc)\n",
        "\n",
        "# 8Ô∏è‚É£ ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_xgb)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"XGBoost (AUC = {auc:.2f})\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve ‚Äì XGBoost\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# üîπ High-Risk Employee Detection\n",
        "# ===============================\n",
        "\n",
        "risk_df_xgb = X_test_sel.copy()\n",
        "risk_df_xgb[\"Attrition_Probability\"] = y_prob_xgb\n",
        "risk_df_xgb[\"Risk_Level\"] = risk_df_xgb[\"Attrition_Probability\"].apply(\n",
        "    lambda x: \"High Risk\" if x >= 0.7 else \"Low Risk\"\n",
        ")\n",
        "\n",
        "print(\"\\nHigh-Risk Employees (Top 5):\")\n",
        "print(risk_df_xgb.sort_values(\"Attrition_Probability\", ascending=False).head())"
      ],
      "metadata": {
        "id": "T46X-T_34BNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# SHAP Analysis for XGBoost (v0.20+ SAFE)\n",
        "# ===============================\n",
        "\n",
        "import shap\n",
        "\n",
        "# Use trained XGBoost model\n",
        "model = xgb_model\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# IMPORTANT: new SHAP API\n",
        "shap_values = explainer(X_test_sel)\n",
        "\n",
        "# ===============================\n",
        "# 1Ô∏è‚É£ Global Feature Importance\n",
        "# ===============================\n",
        "\n",
        "shap.summary_plot(\n",
        "    shap_values.values,\n",
        "    X_test_sel\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ Feature Importance (Bar Plot)\n",
        "# ===============================\n",
        "\n",
        "shap.summary_plot(\n",
        "    shap_values.values,\n",
        "    X_test_sel,\n",
        "    plot_type=\"bar\"\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 3Ô∏è‚É£ Individual Employee Explanation\n",
        "# ===============================\n",
        "\n",
        "employee_index = 4  # change if required\n",
        "\n",
        "shap.plots.waterfall(\n",
        "    shap_values[employee_index]\n",
        ")"
      ],
      "metadata": {
        "id": "_I5nozzG44xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes**"
      ],
      "metadata": {
        "id": "befPHmK2qXpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Naive Bayes Training, Risk Detection & Evaluation\n",
        "# ===============================\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1Ô∏è‚É£ Train Naive Bayes\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_sel, y_train)\n",
        "\n",
        "# 2Ô∏è‚É£ Predictions\n",
        "y_pred_gnb = gnb.predict(X_test_sel)\n",
        "y_prob_gnb = gnb.predict_proba(X_test_sel)[:, 1]\n",
        "\n",
        "# 3Ô∏è‚É£ Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_gnb)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy)\n",
        "\n",
        "# 4Ô∏è‚É£ Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_gnb)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Naive Bayes Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 5Ô∏è‚É£ Precision, Recall, F1 Score\n",
        "precision = precision_score(y_test, y_pred_gnb)\n",
        "recall = recall_score(y_test, y_pred_gnb)\n",
        "f1 = f1_score(y_test, y_pred_gnb)\n",
        "\n",
        "print(\"\\nPrecision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# 6Ô∏è‚É£ Classification Report\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_gnb))\n",
        "\n",
        "# 7Ô∏è‚É£ ROC‚ÄìAUC Score\n",
        "auc = roc_auc_score(y_test, y_prob_gnb)\n",
        "print(\"ROC-AUC Score:\", auc)\n",
        "\n",
        "# 8Ô∏è‚É£ ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_gnb)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"Naive Bayes (AUC = {auc:.2f})\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve ‚Äì Naive Bayes\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# üîπ High-Risk Employee Detection\n",
        "# ===============================\n",
        "\n",
        "risk_df_gnb = X_test_sel.copy()\n",
        "risk_df_gnb[\"Attrition_Probability\"] = y_prob_gnb\n",
        "risk_df_gnb[\"Risk_Level\"] = risk_df_gnb[\"Attrition_Probability\"].apply(\n",
        "    lambda x: \"High Risk\" if x >= 0.7 else \"Low Risk\"\n",
        ")\n",
        "\n",
        "print(\"\\nHigh-Risk Employees (Top 5):\")\n",
        "print(risk_df_gnb.sort_values(\"Attrition_Probability\", ascending=False).head())"
      ],
      "metadata": {
        "id": "-wYrlHk1oma6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZvwghzqpBjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f048d6a"
      },
      "source": [
        "**SHAP ANALYSIS (Naive Bayes)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60e00ac6"
      },
      "source": [
        "# ===============================\n",
        "# Naive Bayes + SHAP (KernelExplainer)\n",
        "# ===============================\n",
        "\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Background data\n",
        "# -------------------------------\n",
        "# Using X_train_sel as background data. Randomly sample 50 instances for efficiency.\n",
        "background = X_train_sel.iloc[np.random.choice(X_train_sel.shape[0], 50, replace=False)]\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ KernelExplainer\n",
        "# -------------------------------\n",
        "# Since GaussianNB has a predict_proba method, we can explain its output.\n",
        "explainer = shap.KernelExplainer(\n",
        "    gnb.predict_proba,\n",
        "    background\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Explain a small test subset\n",
        "# -------------------------------\n",
        "# Use a small subset of X_test_sel for explanation for computational efficiency.\n",
        "X_test_sample_gnb = X_test_sel.iloc[:50]\n",
        "\n",
        "shap_values = explainer.shap_values(X_test_sample_gnb)\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ Global Feature Importance\n",
        "# -------------------------------\n",
        "# For binary classification, we focus on the SHAP values for the positive class (index 1)\n",
        "shap.summary_plot(\n",
        "    shap_values[:, :, 1], # Corrected: Select SHAP values for class 1 for all samples\n",
        "    X_test_sample_gnb\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 5Ô∏è‚É£ Feature Importance (Bar Plot)\n",
        "# -------------------------------\n",
        "shap.summary_plot(\n",
        "    shap_values[:, :, 1], # Corrected: Select SHAP values for class 1 for all samples\n",
        "    X_test_sample_gnb,\n",
        "    plot_type=\"bar\"\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 6Ô∏è‚É£ Individual Employee Explanation\n",
        "# -------------------------------\n",
        "employee_index = 4  # change index if required\n",
        "\n",
        "shap.plots.waterfall(\n",
        "    shap.Explanation(\n",
        "        values=shap_values[employee_index, :, 1], # Corrected: SHAP values for class 1 for a specific employee\n",
        "        base_values=explainer.expected_value[1],\n",
        "        data=X_test_sample_gnb.iloc[employee_index],\n",
        "        feature_names=X_test_sample_gnb.columns\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loggistic Regression"
      ],
      "metadata": {
        "id": "kv9K-qsuqeYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso Regression**"
      ],
      "metadata": {
        "id": "a-1FOdJmqi0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Logistic Regression (Lasso L1 Regularization)\n",
        "# Training, Risk Detection & Evaluation\n",
        "# ===============================\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# ===============================\n",
        "# 1Ô∏è‚É£ Feature Scaling (Important for L1 regularization)\n",
        "# ===============================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_sel)\n",
        "X_test_scaled = scaler.transform(X_test_sel)\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ Train Logistic Regression with L1 Regularization (Lasso)\n",
        "# ===============================\n",
        "\n",
        "# C is the inverse of regularization strength; smaller values specify stronger regularization.\n",
        "# solver='liblinear' supports L1 regularization for binary classification.\n",
        "lasso_lr = LogisticRegression(\n",
        "    penalty='l1',\n",
        "    solver='liblinear',\n",
        "    C=0.1, # You can tune this parameter\n",
        "    random_state=42\n",
        ")\n",
        "lasso_lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# ===============================\n",
        "# 3Ô∏è‚É£ Predictions\n",
        "# ===============================\n",
        "\n",
        "y_pred_lasso = lasso_lr.predict(X_test_scaled)\n",
        "y_prob_lasso = lasso_lr.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# ===============================\n",
        "# 4Ô∏è‚É£ Evaluation Metrics\n",
        "# ===============================\n",
        "\n",
        "print(\"Lasso Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lasso))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_lasso))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_lasso))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_lasso))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob_lasso))\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_lasso))\n",
        "\n",
        "# ===============================\n",
        "# 5Ô∏è‚É£ Confusion Matrix\n",
        "# ===============================\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_lasso)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Lasso Logistic Regression Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 6Ô∏è‚É£ ROC Curve\n",
        "# ===============================\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_lasso)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"Lasso Logistic Regression (AUC = {roc_auc_score(y_test, y_prob_lasso):.2f})\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve ‚Äì Lasso Logistic Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 7Ô∏è‚É£ High-Risk Employee Detection\n",
        "# ===============================\n",
        "\n",
        "risk_df_lasso = X_test_sel.copy()\n",
        "risk_df_lasso[\"Attrition_Probability\"] = y_prob_lasso\n",
        "risk_df_lasso[\"Risk_Level\"] = risk_df_lasso[\"Attrition_Probability\"].apply(\n",
        "    lambda x: \"High Risk\" if x >= 0.7 else \"Low Risk\"\n",
        ")\n",
        "\n",
        "print(\"\\nHigh-Risk Employees (Top 5):\")\n",
        "print(risk_df_lasso.sort_values(\"Attrition_Probability\", ascending=False).head())"
      ],
      "metadata": {
        "id": "KQFhsWzGqSw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b090d687"
      },
      "source": [
        "**SHAP ANALYSIS (Lasso Logistic Regression)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f32609a8"
      },
      "source": [
        "# ===============================\n",
        "# SHAP Analysis for Lasso Logistic Regression (LinearExplainer)\n",
        "# ===============================\n",
        "\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Create SHAP explainer for linear models\n",
        "# -------------------------------\n",
        "# LinearExplainer takes the model and the background data (usually X_train_scaled or a subset)\n",
        "# It uses the coefficients and intercept of the linear model.\n",
        "explainer = shap.LinearExplainer(\n",
        "    lasso_lr,\n",
        "    shap.maskers.Independent(X_train_scaled), # Corrected: Use shap.maskers.Independent\n",
        "    feature_names=X_train_sel.columns # Added feature names for better plots\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Compute SHAP values for the test set\n",
        "# -------------------------------\n",
        "# For LinearExplainer, shap_values is typically a single array for the positive class\n",
        "shap_values = explainer.shap_values(X_test_scaled)\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Convert scaled data back to DataFrame for plotting with feature names\n",
        "# -------------------------------\n",
        "X_test_scaled_df = pd.DataFrame(\n",
        "    X_test_scaled,\n",
        "    columns=X_test_sel.columns\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 4Ô∏è‚É£ Global Feature Importance (Summary Plot)\n",
        "# ===============================\n",
        "# For LinearExplainer with a binary model, shap_values is already for the positive class.\n",
        "shap.summary_plot(\n",
        "    shap_values, # Corrected: Pass shap_values directly (it's already a matrix for class 1)\n",
        "    X_test_scaled_df\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 5Ô∏è‚É£ Feature Importance (Bar Plot)\n",
        "# ===============================\n",
        "shap.summary_plot(\n",
        "    shap_values, # Corrected: Pass shap_values directly\n",
        "    X_test_scaled_df,\n",
        "    plot_type=\"bar\"\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 6Ô∏è‚É£ Individual Employee Explanation (Force Plot)\n",
        "# ===============================\n",
        "\n",
        "employee_index = 4  # change index if required\n",
        "\n",
        "shap.plots.force(\n",
        "    explainer.expected_value, # Corrected: Use explainer.expected_value directly (it's a scalar)\n",
        "    shap_values[employee_index], # Corrected: Access SHAP values for the employee directly\n",
        "    X_test_scaled_df.iloc[employee_index]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Regression**"
      ],
      "metadata": {
        "id": "EZv0xk5ErUu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Logistic Regression (Ridge L2 Regularization)\n",
        "# Training, Risk Detection & Evaluation\n",
        "# ===============================\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# ===============================\n",
        "# 1Ô∏è‚É£ Feature Scaling (Important for L2 regularization)\n",
        "# ===============================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_sel)\n",
        "X_test_scaled = scaler.transform(X_test_sel)\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ Train Logistic Regression with L2 Regularization (Ridge)\n",
        "# ===============================\n",
        "\n",
        "# C is the inverse of regularization strength; smaller values specify stronger regularization.\n",
        "# solver='liblinear' supports L2 regularization for binary classification.\n",
        "ridge_lr = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    solver='liblinear',\n",
        "    C=1.0, # You can tune this parameter\n",
        "    random_state=42\n",
        ")\n",
        "ridge_lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# ===============================\n",
        "# 3Ô∏è‚É£ Predictions\n",
        "# ===============================\n",
        "\n",
        "y_pred_ridge = ridge_lr.predict(X_test_scaled)\n",
        "y_prob_ridge = ridge_lr.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# ===============================\n",
        "# 4Ô∏è‚É£ Evaluation Metrics\n",
        "# ===============================\n",
        "\n",
        "print(\"Ridge Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_ridge))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_ridge))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_ridge))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_ridge))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob_ridge))\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_ridge))\n",
        "\n",
        "# ===============================\n",
        "# 5Ô∏è‚É£ Confusion Matrix\n",
        "# ===============================\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_ridge)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Ridge Logistic Regression Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 6Ô∏è‚É£ ROC Curve\n",
        "# ===============================\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_ridge)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"Ridge Logistic Regression (AUC = {roc_auc_score(y_test, y_prob_ridge):.2f})\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve ‚Äì Ridge Logistic Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 7Ô∏è‚É£ High-Risk Employee Detection\n",
        "# ===============================\n",
        "\n",
        "risk_df_ridge = X_test_sel.copy()\n",
        "risk_df_ridge[\"Attrition_Probability\"] = y_prob_ridge\n",
        "risk_df_ridge[\"Risk_Level\"] = risk_df_ridge[\"Attrition_Probability\"].apply(\n",
        "    lambda x: \"High Risk\" if x >= 0.7 else \"Low Risk\"\n",
        ")\n",
        "\n",
        "print(\"\\nHigh-Risk Employees (Top 5):\")\n",
        "print(risk_df_ridge.sort_values(\"Attrition_Probability\", ascending=False).head())"
      ],
      "metadata": {
        "id": "5YOjPOKHrZEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "590a1b3d"
      },
      "source": [
        "**SHAP ANALYSIS (Ridge Logistic Regression)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0c1e2f9"
      },
      "source": [
        "# ===============================\n",
        "# SHAP Analysis for Ridge Logistic Regression (LinearExplainer)\n",
        "# ===============================\n",
        "\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Create SHAP explainer for linear models\n",
        "# -------------------------------\n",
        "# LinearExplainer takes the model and the background data (usually X_train_scaled or a subset)\n",
        "# It uses the coefficients and intercept of the linear model.\n",
        "explainer = shap.LinearExplainer(\n",
        "    ridge_lr,\n",
        "    shap.maskers.Independent(X_train_scaled), # Use shap.maskers.Independent for background data\n",
        "    feature_names=X_train_sel.columns # Added feature names for better plots\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Compute SHAP values for the test set\n",
        "# -------------------------------\n",
        "# For LinearExplainer, shap_values is typically a single array for the positive class\n",
        "shap_values = explainer.shap_values(X_test_scaled)\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Convert scaled data back to DataFrame for plotting with feature names\n",
        "# -------------------------------\n",
        "X_test_scaled_df = pd.DataFrame(\n",
        "    X_test_scaled,\n",
        "    columns=X_test_sel.columns\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 4Ô∏è‚É£ Global Feature Importance (Summary Plot)\n",
        "# ===============================\n",
        "# For LinearExplainer with a binary model, shap_values is already for the positive class.\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_test_scaled_df\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 5Ô∏è‚É£ Feature Importance (Bar Plot)\n",
        "# ===============================\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_test_scaled_df,\n",
        "    plot_type=\"bar\"\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 6Ô∏è‚É£ Individual Employee Explanation (Force Plot)\n",
        "# ===============================\n",
        "\n",
        "employee_index = 4  # change index if required\n",
        "\n",
        "shap.plots.force(\n",
        "    explainer.expected_value,\n",
        "    shap_values[employee_index],\n",
        "    X_test_scaled_df.iloc[employee_index]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MIX**"
      ],
      "metadata": {
        "id": "hoAQ1698r1jd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gktxR5EMr4dx"
      },
      "source": [
        "# ===============================\n",
        "# Logistic Regression (Elastic Net L1 + L2 Regularization)\n",
        "# Training, Risk Detection & Evaluation\n",
        "# ===============================\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# ===============================\n",
        "# 1Ô∏è‚É£ Feature Scaling (Important for Regularization)\n",
        "# ===============================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_sel)\n",
        "X_test_scaled = scaler.transform(X_test_sel)\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ Train Logistic Regression with Elastic Net Regularization\n",
        "# ===============================\n",
        "\n",
        "# penalty='elasticnet' combines L1 and L2.\n",
        "# solver='saga' is required for elasticnet penalty.\n",
        "# l1_ratio: The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1.\n",
        "# l1_ratio = 0 is equivalent to L2 (Ridge), l1_ratio = 1 is equivalent to L1 (Lasso).\n",
        "# C is the inverse of regularization strength; smaller values specify stronger regularization.\n",
        "elastic_lr = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    l1_ratio=0.5, # Adjust this value (0 to 1) for the mix of L1 and L2\n",
        "    C=0.1, # You can tune this parameter\n",
        "    random_state=42,\n",
        "    max_iter=1000 # Increase max_iter for convergence if needed\n",
        ")\n",
        "elastic_lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# ===============================\n",
        "# 3Ô∏è‚É£ Predictions\n",
        "# ===============================\n",
        "\n",
        "y_pred_elastic = elastic_lr.predict(X_test_scaled)\n",
        "y_prob_elastic = elastic_lr.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# ===============================\n",
        "# 4Ô∏è‚É£ Evaluation Metrics\n",
        "# ===============================\n",
        "\n",
        "print(\"Elastic Net Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_elastic))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_elastic))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_elastic))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_elastic))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob_elastic))\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_elastic))\n",
        "\n",
        "# ===============================\n",
        "# 5Ô∏è‚É£ Confusion Matrix\n",
        "# ===============================\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_elastic)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Elastic Net Logistic Regression Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 6Ô∏è‚É£ ROC Curve\n",
        "# ===============================\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_elastic)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"Elastic Net Logistic Regression (AUC = {roc_auc_score(y_test, y_prob_elastic):.2f})\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve ‚Äì Elastic Net Logistic Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 7Ô∏è‚É£ High-Risk Employee Detection\n",
        "# ===============================\n",
        "\n",
        "risk_df_elastic = X_test_sel.copy()\n",
        "risk_df_elastic[\"Attrition_Probability\"] = y_prob_elastic\n",
        "risk_df_elastic[\"Risk_Level\"] = risk_df_elastic[\"Attrition_Probability\"].apply(\n",
        "    lambda x: \"High Risk\" if x >= 0.7 else \"Low Risk\"\n",
        ")\n",
        "\n",
        "print(\"\\nHigh-Risk Employees (Top 5):\")\n",
        "print(risk_df_elastic.sort_values(\"Attrition_Probability\", ascending=False).head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06f12d5c"
      },
      "source": [
        "**SHAP ANALYSIS (Elastic Net Logistic Regression)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbbd6236"
      },
      "source": [
        "# ===============================\n",
        "# SHAP Analysis for Elastic Net Logistic Regression (LinearExplainer)\n",
        "# ===============================\n",
        "\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Create SHAP explainer for linear models\n",
        "# -------------------------------\n",
        "# LinearExplainer takes the model and the background data (usually X_train_scaled or a subset)\n",
        "# It uses the coefficients and intercept of the linear model.\n",
        "explainer = shap.LinearExplainer(\n",
        "    elastic_lr,\n",
        "    shap.maskers.Independent(X_train_scaled), # Use shap.maskers.Independent for background data\n",
        "    feature_names=X_train_sel.columns # Added feature names for better plots\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Compute SHAP values for the test set\n",
        "# -------------------------------\n",
        "# For LinearExplainer, shap_values is typically a single array for the positive class\n",
        "shap_values = explainer.shap_values(X_test_scaled)\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Convert scaled data back to DataFrame for plotting with feature names\n",
        "# -------------------------------\n",
        "X_test_scaled_df = pd.DataFrame(\n",
        "    X_test_scaled,\n",
        "    columns=X_test_sel.columns\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 4Ô∏è‚É£ Global Feature Importance (Summary Plot)\n",
        "# ===============================\n",
        "# For LinearExplainer with a binary model, shap_values is already for the positive class.\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_test_scaled_df\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 5Ô∏è‚É£ Feature Importance (Bar Plot)\n",
        "# ===============================\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_test_scaled_df,\n",
        "    plot_type=\"bar\"\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 6Ô∏è‚É£ Individual Employee Explanation (Force Plot)\n",
        "# ===============================\n",
        "\n",
        "employee_index = 4  # change index if required\n",
        "\n",
        "shap.plots.force(\n",
        "    explainer.expected_value,\n",
        "    shap_values[employee_index],\n",
        "    X_test_scaled_df.iloc[employee_index]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}